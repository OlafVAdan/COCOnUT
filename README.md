# COCOnUT; a messy Java Processing code that reveals how topic modeling unfolds in real time. 
COCOnUT is the result of an attempt to create a tool that automatically generates a mindmap from conversational content; COrrelating COnversational (n)-Utterances.
Aside from the Processing (JAVA) code created from scratch, it makes use of the 'react-speech-sample' provided in Azure Cognitive Services (ACS) documentation (see:https://github.com/Azure-Samples/AzureSpeechReactSample), modified to transcribe text to speech continuously (see:UML_diagrams_and_visualized_output). In addition, the modified speech sample integrates 'Named Entity Recognition' (NER) and 'key-phrase extraxtion' (KPE) modules provided by ASC 'Text Analysis'.

The modified 'react-speech-sample' creates an addition local server to facilitate communication with Processing (see www.processing.org), in which the last recognized speech (from here on defined as 'Utterance'), and corresponding NER and KPE results, are stored in a JSONObject with keys 'sentence', 'entities' and 'keyphrases' respectively. The Proccessing code requests this object every 2000ms, after which the requested object is processed to remove duplicate results from KPE & NER (see: $IMAGE). Which information was generated by what ACS-module is recorded; by saving retrieved objects in and array of nameless 'Stated' objects (created by the 'Stated' class). 

APPROACH
The approach taken towards generating a mindmap is based on the assumption that a single utterance (or 'construal' as defined by X, see:$source) by an individual contains specific information to their sensemaking process, for which a stream of these may reveal sensemaking processes. As such, the string array generated after removing duplicates is further processed to keep track of how often each extracted segment is mentioned across all collected Utterances (i.e. object created from 'Countedkewlib' class), as well as which segments occured in the same Utterance and how often this happened (i.e object created from 'Wordcons' class).

VISUALIZED
The segment (main segment) with the most segments in direct relation (1st degree) to it, as well as these 1st degree segments are then visualized 'in a nutshell'. The segments identified in relation to the '1st degree' segments, but NOT to the 'main segment' (2nd degree) are vizualized outside the coconut.


In hindsight, I learned it is basically a live topic modelling algorithm that shows similarities with PAM and TOT topic modeling algorithms; the latter also defining an utterance as a 'document'. 


